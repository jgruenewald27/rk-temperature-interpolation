---
title: "RK_MLR_loop_monthly_timestamps"
output: html_document
date: "2025-10-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Load Required Libraries}

# Load Required Libraries

# Spatial Data Handling & Processing
library(sf)
library(sp)
library(terra)
library(raster)
library(stars)
library(spdep)

# Spatial Analysis & Interpolation
library(gstat)
library(randomForest)
library(nlme)
library(automap)
library(mgcv)

# Data Manipulation & Wrangling
library(tidyverse)

# Data Visualization
library(ggplot2)
library(scales)
library(gridExtra)
library(corrplot)

# Mapping & Interactive Visualization
library(tmap)

# Additional
library(lattice)
library(car)
```

--------------------------------------------------------------------------------

```{r Load and preprocess data}

# Read temperature data for the entire year of 2023
temp <- sf::read_sf("../data/temp_HD/sensor_data_year_2023.geojson")

# Removes rows where temp is NA
temp <- temp %>% filter(!is.na(temperature))

# Reproject the data for Germany
temp <- st_transform(temp, crs="EPSG:32632")

# Clean the data from outliers -> currently working with hard, manual breaks
# Currently nothing is removed by this step because no measurements are above 40°C for the year 2023
temp_clean <- temp %>% filter(temperature >= -35, temperature <= 40)

# Drop all measurement stations which didn't collect data the entire year around
temp_clean_station <- temp_clean %>%
  mutate(dateobserved = as.POSIXct(dateobserved, tz = "Europe/Berlin")) %>%
  filter(!entity_id %in% c(
    "hd:DE_Heidelberg_69120_12:WeatherObserved",
    "hd:DE_Heidelberg_69120_34:WeatherObserved",
    "hd:DE_Heidelberg_69123_41:WeatherObserved",
    "hd:DE_Gaiberg_69251_21:WeatherObserved",
    "hd:DE_Heidelberg_46:WeatherObserved"
  ))

# Check if exactly 5 stations were dropped
cat("Number of stations BEFORE cleaning: ",
    length(unique(na.omit(temp_clean$entity_id))), "\n")

cat("Number of stations AFTER cleaning:  ",
    length(unique(na.omit(temp_clean_station$entity_id))), "\n")

# Calculate monthly mean temp for the year 2023
temp_monthly_mean_2023 <- temp_clean_station %>%
  filter(year(dateobserved) == 2023) %>%
  mutate(month = floor_date(dateobserved, "month")) %>%
  group_by(entity_id, month) %>%
  summarise(
    mm_temp = mean(temperature, na.rm = TRUE),  
    sd_temp   = sd(temperature, na.rm = TRUE), 
    n_obs     = n(),                              
    .groups   = "drop"
  )

```

```{r}

# Import AOI and station coords
hd_bounds <- sf::read_sf('../data/AOI/OSM_boundaries_HD.geojson')
station_coords_sf <- sf::read_sf('../data/temp_HD/station_coords.gpkg')

# Import the covariates
dem <- terra::rast("../data/DEM/hd_elevation_4326.tif")
tch <- terra::rast("../data/canopy_height/hd_canopy_height_4326.tif")
ghs_bh <- terra::rast("../data/building_height/hd_building_height_4326.tif")

# Mask out all values which are assigned to water and have value 101
# Not part of this area. But needs to be masked as well: 102 Snow/ice; 103 No data
tch[tch == 101] <- NA

# Reproject the data
hd_bounds <- st_transform(hd_bounds, crs = st_crs(temp_monthly_mean_2023))
station_coords_sf <- st_transform(station_coords_sf, crs = st_crs(temp_monthly_mean_2023))
dem <- terra::project(dem, y = crs(temp_monthly_mean_2023))
tch <- terra::project(tch, y = crs(temp_monthly_mean_2023))
ghs_bh <- terra::project(ghs_bh, y = crs(temp_monthly_mean_2023))

# Check if any CRS mismatches
if (!identical(crs(tch), crs(dem))) {
  stop("CRS mismatch: Tree canopy height and DEM don't have the same CRS.")
}
if (!identical(crs(ghs_bh), crs(dem))) {
  stop("CRS mismatch: Building height and DEM don't have the same CRS.")
}
cat("All covariates share the same CRS.\n")

# Convert to SpatialPointsDataFrame
station_coords <- as(station_coords_sf, "Spatial")

# Create a Raster Stack for all covariate information
cat("Checking input raster resolutions in metres:\n")
cat(sprintf("DEM:    %.2f x %.2f\n", terra::res(dem)[1], terra::res(dem)[2]))
cat(sprintf("TCH:    %.2f x %.2f\n", terra::res(tch)[1], terra::res(tch)[2]))
cat(sprintf("GHS_BH: %.2f x %.2f\n\n", terra::res(ghs_bh)[1], terra::res(ghs_bh)[2]))

# Align canopy height and building height to DEM resolution and extent
tch_aligned    <- terra::resample(tch, dem, method = "bilinear")
ghs_bh_aligned <- terra::resample(ghs_bh, dem, method = "near")

# Check alignment after resampling
if (!terra::compareGeom(dem, tch_aligned, ghs_bh_aligned, stopOnError = FALSE)) {
  stop("Covariate rasters are not perfectly aligned after resampling. Check extent/resolution/CRS.")
}

# Combine layers into a single SpatRaster stack
env_stack <- c(dem, tch_aligned, ghs_bh_aligned)

# Rename layers for clarity
names(env_stack) <- c("elevation", "canopy_height", "building_height")

# Code to include lat and lon information in raster stack

# Also add lat and lon to the raster stack
# Create coordinate rasters
lon <- terra::xFromCell(env_stack, 1:ncell(env_stack))
lat <- terra::yFromCell(env_stack, 1:ncell(env_stack))

# Convert to raster layers
lon_raster <- dem
lat_raster <- dem
values(lon_raster) <- lon
values(lat_raster) <- lat
names(lon_raster) <- "lon"
names(lat_raster) <- "lat"

# Stack the three raster layers
grids <- c(env_stack, lon_raster, lat_raster)

# Preparation of grid as a covariate for running RK
grids_ras <- stack(grids)

# Convert to SpatialGridDataFrame
grids_sp <- as(grids_ras, "SpatialGridDataFrame")
```

--------------------------------------------------------------------------------

```{r create_output_folder}
output_dir <- "../RK_Monthly_Mean"
if (!dir.exists(output_dir)) dir.create(output_dir)

# Define subdirectories for specific output types
variogram_dir <- file.path(output_dir, "variogram")
cv_dir        <- file.path(output_dir, "cross_validation")
rk_dir        <- file.path(output_dir, "rk_predictions")

# Create subdirectories if they don't exist
dir.create(variogram_dir, showWarnings = FALSE)
dir.create(cv_dir, showWarnings = FALSE)
dir.create(rk_dir, showWarnings = FALSE)

ts_to_posix <- function(ch) {
  if (inherits(ch, "POSIXt")) return(ch)
  if (is.numeric(ch)) return(as.POSIXct(ch * 3600, origin = "1970-01-01", tz = tz_berlin))
  as.POSIXct(ch, format = "%Y-%m-%d %H:%M:%S", tz = tz_berlin)
}
```

```{r main_loop}

# Get unique time stamps
timestamps <- unique(temp_monthly_mean_2023$month)[1:12]  

# Counters + progress bar
total     <- length(timestamps)                       
completed <- 0L                                     
skipped   <- 0L                                      
pb <- txtProgressBar(min = 0, max = total, style = 3)
cat(sprintf("Processing %d timestamps…\n", total))

# Loop through each time stamp
total_metrics <- data.frame()

for (i in seq_along(timestamps)) {                           
  ts <- timestamps[i]                                    
  dt_local <- ts                          # already POSIXct
  dt_lab   <- format(dt_local, "%Y-%m")   # e.g. "2023-01"
  dt_file  <- format(dt_local, "%Y_%m")   # safe for filenames
  cat(sprintf("\n[%d/%d] Processing: timestamp = %s\n", i, total, dt_lab))   

  # ------------------------------------------------
  # STEP 1: Filter hourly data and extract covariates from spatial grid
  # ------------------------------------------------
  
  # Select temperature data for the current hour
  sel_temp_hm <- temp_monthly_mean_2023 %>%
    filter(month == ts)
  
  # Skip if fewer than 20 data points for current hour
  if (nrow(sel_temp_hm) < 20) {                                 
    skipped <- skipped + 1L                                       
    cat("  → skipped (n < 20)\n")                          
    next                                                         
  }
  
  # Ensure sel_temp_hm is sf and POINT (one row per point)
  sel_temp_hm <- st_as_sf(sel_temp_hm)
  sel_temp_hm <- st_cast(sel_temp_hm, "POINT", warn = FALSE)  # avoid MULTIPOINT -> multiple rows
    
  # Convert Spatial object to RasterBrick
  r_brick <- brick(grids_sp)
  
  # Convert RasterBrick to terra SpatRaster object
  grid_terra <- rast(r_brick)
  
  # Extract raster values at the point locations
  extracted_vals <- terra::extract(grid_terra, sel_temp_hm, ID = FALSE)

  cat("\n>>> Month:", ts, "\n")
  cat("sel_temp_hm rows:", nrow(sel_temp_hm), "\n")
  cat("extracted_vals rows:", nrow(extracted_vals), "\n")
  
  if (nrow(sel_temp_hm) != nrow(extracted_vals)) {
    cat("⚠️ Mismatch detected for month", ts, 
        "(", nrow(sel_temp_hm), "vs", nrow(extracted_vals), ")\n")
  }
  
  # Identify any stations where extraction returned NA
  bad_rows <- which(!complete.cases(extracted_vals))
  if (length(bad_rows) > 0) {
    cat("Stations with missing raster data:\n")
    print(sel_temp_hm$entity_id[bad_rows])
  }
  
  # Combine the point data with the extracted raster values
  temp_shm.ex <- cbind(as.data.frame(sel_temp_hm), extracted_vals)
  
  # ------------------------------------------------
  # STEP 2: Fit MLR
  # ------------------------------------------------
  
  # Fit multiple linear regression model
  lm.temp_shm <- lm(mm_temp ~ elevation + canopy_height + building_height, data = temp_shm.ex)
  summary_lm <- summary(lm.temp_shm)
  
  # Compute residuals and predictions
  pred <- predict(lm.temp_shm, temp_shm.ex)
  resid <- temp_shm.ex$mm_temp - pred
  
  # Extract metrics
  model_metrics <- data.frame(
    timestamp      = ts,
    r_squared      = summary_lm$r.squared,
    adj_r_squared  = summary_lm$adj.r.squared,
    f_statistic    = summary_lm$fstatistic[1],
    f_pvalue       = pf(summary_lm$fstatistic[1],
                        summary_lm$fstatistic[2],
                        summary_lm$fstatistic[3],
                        lower.tail = FALSE),
    residual_se    = summary_lm$sigma,
    rmse           = sqrt(mean(resid^2)),
    mae            = mean(abs(resid)),
    AIC            = AIC(lm.temp_shm),
    BIC            = BIC(lm.temp_shm)
  )
  
  # Append to tracking data frame
  if (!exists("lm_metrics_all")) {
    lm_metrics_all <- model_metrics
  } else {
    lm_metrics_all <- rbind(lm_metrics_all, model_metrics)
  }

  # Save model's residuals back into original df as new column
  temp_shm.ex$residuals <- resid
  
  # Convert df into spatial object using existing geometry and
  # Convert MULTIPOINT geometries to POINT
  temp_shm.sf <- st_as_sf(temp_shm.ex) |> st_cast("POINT")
  
  st_crs(temp_shm.sf) <- st_crs(grids_sp)
  
  # ------------------------------------------------
  # STEP 3: Compute anisotropy & fit directional variogram
  # ------------------------------------------------
  
  # Compute empirical variogram map of model residuals
  # This helps visualize spatial autocorrelation in all directions
  varmap <- variogram(residuals ~ 1, data = temp_shm.sf, map = TRUE,
                    # cutoff is half the spatial extent (or diameter) of the study area
                    cutoff = sqrt(areaSpatialGrid(grids_sp)) / 2, 
                    # scaled relative to the resolution of the grid
                    width = 30 * grids_sp@grid@cellsize[1])

  # Store cutoff and bin width values for reuse and labeling
  cutoff_val <- sqrt(areaSpatialGrid(grids_sp)) / 2
  width_val  <- 30 * grids_sp@grid@cellsize[1]
  
  # Report how many rows are in variogram map
  cat("Variogram map has", nrow(as.data.frame(varmap)), "rows\n")
  
  # Define output filename for the variogram map plot
  file_varmap <- file.path(variogram_dir, paste0(dt_file, "_variogram_map.png"))  
  
  # Plot and save the directional variogram map
  png(file_varmap, width = 8, height = 6, units = "in", res = 300)
  print(
    plot(varmap,
         col.regions = grey(rev(seq(0, 1, 0.025))),
         main = sprintf("Directional Variogram Map (cutoff: %.1f km, width: %.1f km)\n%s",  
                        cutoff_val / 1000, width_val / 1000, dt_lab))
  )
  dev.off()
  
  # Compute directional variograms for North–South (0°) and East–West (90°)
  rv.temp <- variogram(residuals ~ 1, temp_shm.sf, alpha = c(0, 45, 90, 135))

  # Fit theoretical exponential variogram model to the directional variogram
  # Compute experimental variogram
  rv.temp <- variogram(residuals ~ 1, temp_shm.sf)
  
  # Try several initial models and pick the best fit
  init_models <- list(
    vgm("Sph"),
    vgm("Exp"),
    vgm("Gau")
  )
  
  fit_list <- lapply(init_models, function(m) fit.variogram(rv.temp, m))
  fit_errors <- sapply(fit_list, attr, "SSErr")
  rvgm.temp <- fit_list[[which.min(fit_errors)]]

  
  # Define output filename for directional variogram fit plot
  file_varfit <- file.path(variogram_dir, paste0(dt_file, "_directional_variogram_fit.png"))  
 
  # Plot the empirical and fitted directional variograms and save
  png(file_varfit, width = 8, height = 6, units = "in", res = 300)
  print(
    plot(rv.temp, rvgm.temp,
         main = paste0("Directional Variogram Fit (0°, 45°, 90°, 135°)\n", dt_lab),   
         plot.nu = FALSE, cex = 1.5, pch = "+", col = "black")
  )
  dev.off()
  
  # ------------------------------------------------
  # STEP 4a: Cross-validation of residual kriging model
  # ------------------------------------------------

  # Perform leave-one-out cross-validation (LOOCV) of the kriging model
  cv_resid <- krige.cv(residuals ~ 1,
                       locations = temp_shm.sf,
                       model = rvgm.temp,
                       nfold = nrow(temp_shm.sf),   # one fold per observation = LOOCV
                       nmax = 10)                   # max number of neighbors used for prediction
  
  # Compute CV metrics
  cv_rmse <- sqrt(mean(cv_resid$residual^2))
  cv_mae  <- mean(abs(cv_resid$residual))
  cv_me   <- mean(cv_resid$residual)
  
  cat("CV RMSE:", round(cv_rmse, 2), "\n")
  cat("CV MAE :", round(cv_mae, 2), "\n")
  cat("CV Bias:", round(cv_me, 2), "\n")
  
  # Create df with CV metrics for current timestamp
  cv_metrics <- data.frame(
    timestamp = ts,
    cv_rmse   = cv_rmse,
    cv_mae    = cv_mae,
    cv_bias   = cv_me
  )
  
  # Append metrics to tracking df across all time steps
  if (!exists("cv_metrics_all")) {
    cv_metrics_all <- cv_metrics
  } else {
    cv_metrics_all <- rbind(cv_metrics_all, cv_metrics)
  }
  
  # Create and save scatterplot of predicted vs residual values from CV
  p_cv <- ggplot(cv_resid, aes(x = var1.pred, y = residual)) +
    geom_point() +
    geom_hline(yintercept = 0, linetype = "dashed") +
    labs(title = paste("Cross-validation Residuals\n", dt_lab), x = "Predicted", y = "Residual") +  
    theme_minimal(base_size = 12)
  
  ggsave(filename = file.path(cv_dir, paste0(dt_file, "_cv_residuals_plot.png")),  
         plot = p_cv, width = 8, height = 6, dpi = 300)
  
  # ------------------------------------------------
  # STEP 4b: LOOCV for full RK
  # ------------------------------------------------

  cv_rk <- krige.cv(
    formula   = mm_temp ~ elevation + canopy_height + building_height,
    locations = temp_shm.sf,
    model     = rvgm.temp,                 # variogram of residuals
    nfold     = nrow(temp_shm.sf),         # LOOCV
    nmax      = 10
  )

  # krige.cv returns: observed, var1.pred, residual (= observed - predicted)

  rk_cv_rmse <- sqrt(mean(cv_rk$residual^2))
  rk_cv_mae  <- mean(abs(cv_rk$residual))
  rk_cv_bias <- mean(cv_rk$residual)

  cat("RK LOOCV RMSE:", round(rk_cv_rmse, 2),
      "MAE:", round(rk_cv_mae, 2),
      "Bias:", round(rk_cv_bias, 2), "\n")

  # Store RK CV results
  rk_cv_metrics <- data.frame(
    timestamp   = ts,
    rk_cv_rmse  = rk_cv_rmse,
    rk_cv_mae   = rk_cv_mae,
    rk_cv_bias  = rk_cv_bias
  )

  if (!exists("rk_cv_metrics_all")) {
    rk_cv_metrics_all <- rk_cv_metrics
  } else {
    rk_cv_metrics_all <- rbind(rk_cv_metrics_all, rk_cv_metrics)
  }

  # Plot RK CV residuals
  p_rk_cv <- ggplot(cv_rk, aes(x = var1.pred, y = residual)) +
    geom_point() +
    geom_hline(yintercept = 0, linetype = "dashed") +
    labs(
      title = paste("RK LOOCV Residuals\n", dt_lab),
      x     = "RK predicted (°C)",
      y     = "Residual (Observed - Predicted)"
    ) +
    theme_minimal(base_size = 12)

  ggsave(
    filename = file.path(cv_dir, paste0(dt_file, "_rk_loocv_residuals_plot.png")),
    plot     = p_rk_cv,
    width    = 8, height = 6, dpi = 300
  )

  # ------------------------------------------------
  # STEP 5: Predict regression trend and kriging residuals
  # ------------------------------------------------
    
  # Define a gstat object for kriging using the fitted residual variogram
  g.resid <- gstat(
    id = c("residuals"),
    formula = residuals ~ 1,
    data = temp_shm.sf,
    nmax = 31,
    model = rvgm.temp
  )
  
  # Predict the temperature trend component using the regression model
  locTEMP.reg <- predict(lm.temp_shm, grids_sp)
  
  # OK of the regression residuals to model spatial autocorrelation
  locTEMP <- predict(g.resid, grids_sp, beta=1, BLUE=FALSE)
  
  # Combine the regression prediction with kriged residuals to get final RK predictions
  rk.pred <- locTEMP.reg + locTEMP$residuals.pred
  
  # Add the RK predictions as a new variable to the spatial grid object
  grid_out <- grids_sp
  grids_sp$rk_pred <- rk.pred
  
  # Convert SpatialPixelsDataFrame → SpatRaster for export
  rk_raster <- terra::rast(grids_sp["rk_pred"])
  
  # Define output .tif path
  rk_file_tif <- file.path(rk_dir, paste0(dt_file, "_rk_prediction_map.tif"))
  
  # Write GeoTIFF
  terra::writeRaster(
    rk_raster,
    filename = rk_file_tif,
    overwrite = TRUE,
    gdal = c("COMPRESS=LZW")  # optional compression
  )
  
  cat("  → RK prediction saved as GeoTIFF:", rk_file_tif, "\n")
  
  # Define output filename for the RK prediction map
  rk_file_img <- file.path(rk_dir, paste0(dt_file, "_rk_prediction_map", ".png"))   
  
  # Generate and save the RK prediction map
  png(rk_file_img, width = 8, height = 6, units = "in", res = 300)
  print(
    spplot(grids_sp, "rk_pred",
           main = paste("Regression Kriging Prediction (°C)\n", dt_lab),   
           sp.layout = list("sp.points", station_coords, pch = 20, col = "white"))
  )
  dev.off()
  
  # ------------------------------------------------
  # STEP 6: Evaluate RK predictions at observation stations
  # ------------------------------------------------
  
  # Match station coordinates with observed stations only
  obs_coords <- st_coordinates(temp_shm.sf)
  
  # Convert to SpatialPoints object with same CRS as prediction grid
  obs_stations <- SpatialPoints(coords = obs_coords, proj4string = CRS(proj4string(grids_sp)))
  
  # Extract only at observed station locations
  rk_at_obs <- sp::over(obs_stations, grids_sp)
  
  # Combine predictions with observations
  rk_eval <- cbind(rk_at_obs, obs = temp_shm.sf$mm_temp)

  # Check if predicted and observed data match in length
  cat("Predicted rows:", nrow(rk_at_obs), "\n")
  cat("Observed rows :", length(temp_shm.sf$mm_temp), "\n")
  
  # Calculate prediction error
  rk_eval$residual <- rk_eval$obs - rk_eval$rk_pred
  
  # Calculate evaluation metrics for RK performance
  rmse <- sqrt(mean(rk_eval$residual^2, na.rm = TRUE))
  mae  <- mean(abs(rk_eval$residual), na.rm = TRUE)
  bias <- mean(rk_eval$residual, na.rm = TRUE)
  
  cat("RK RMSE :", round(rmse, 2), "\n")
  cat("RK MAE  :", round(mae, 2), "\n")
  cat("RK Bias :", round(bias, 2), "\n")
  
  # Store metrics in df for current timestamp
  rk_metrics <- data.frame(
    timestamp = ts,
    rk_rmse   = rmse,
    rk_mae    = mae,
    rk_bias   = bias
  )
  
  # Append metrics to cumulative RK metrics tracking object
  if (!exists("rk_metrics_all")) {
    rk_metrics_all <- rk_metrics
  } else {
    rk_metrics_all <- rbind(rk_metrics_all, rk_metrics)
  }
  
  # Save RK residuals plot
  rk_resid_plot <- ggplot(rk_eval, aes(x = rk_pred, y = residual)) +
    geom_point() +
    geom_hline(yintercept = 0, linetype = "dashed") +
    labs(title = paste("RK Prediction Residuals at Stations\n", dt_lab),   
         x = "RK Predicted (°C)", y = "Residual (Observed - Predicted)") +
    theme_minimal(base_size = 12)
  
  ggsave(filename = file.path(rk_dir, paste0(dt_file, "_rk_residuals_plot.png")),  
         plot = rk_resid_plot, width = 8, height = 6, dpi = 300)
  
  completed <- completed + 1L 
  setTxtProgressBar(pb, completed)
  cat("\n")
  cat(sprintf("  → done. Completed: %d/%d (skipped: %d)\n",      
              completed, total, skipped))                        
}

# ------------------------------------------------
# STEP 7: Finalize and save results
# ------------------------------------------------


# Close progress bar + final summary
close(pb)                                                        
cat(sprintf("\nFinished. Completed: %d/%d | Skipped: %d\n",       
            completed, total, skipped))                         

# Save MLR metrics
metrics_file <- file.path(output_dir, "lm_model_performance_summary.csv")
if (exists("lm_metrics_all")) {
  lm_metrics_all$month <- format(
    as.POSIXct(lm_metrics_all$timestamp, origin = "1970-01-01", tz = "Europe/Berlin"),
    "%Y-%m"
  )
  # Put month first; drop raw timestamp if you don't want it in the file
  lm_out <- lm_metrics_all[, c("month", setdiff(names(lm_metrics_all), c("month", "timestamp")))]
  write.csv(lm_out, metrics_file, row.names = FALSE)
}

# Save CV metrics
cv_file <- file.path(output_dir, "cross_validation_metrics.csv")
if (exists("cv_metrics_all")) {
  cv_metrics_all$month <- format(
    as.POSIXct(cv_metrics_all$timestamp, origin = "1970-01-01", tz = "Europe/Berlin"),
    "%Y-%m"
  )
  cv_out <- cv_metrics_all[, c("month", setdiff(names(cv_metrics_all), c("month", "timestamp")))]
  write.csv(cv_out, cv_file, row.names = FALSE)
}

# Save RK LOOCV metrics
rk_cv_file <- file.path(output_dir, "rk_loocv_metrics.csv")
if (exists("rk_cv_metrics_all")) {
  rk_cv_metrics_all$datetime_local <- ts_to_posix(rk_cv_metrics_all$timestamp)
  rk_cv_metrics_all <- rk_cv_metrics_all %>%
    relocate(datetime_local, .after = timestamp)
  write.csv(rk_cv_metrics_all, rk_cv_file, row.names = FALSE)
}

# Save RK metrics
rk_file <- file.path(output_dir, "rk_metrics.csv")
if (exists("rk_metrics_all")) {
  rk_metrics_all$month <- format(
    as.POSIXct(rk_metrics_all$timestamp, origin = "1970-01-01", tz = "Europe/Berlin"),
    "%Y-%m"
  )
  rk_out <- rk_metrics_all[, c("month", setdiff(names(rk_metrics_all), c("month", "timestamp")))]
  write.csv(rk_out, rk_file, row.names = FALSE)
}
```

------------------------------------------------------------------------

Plots to analyse model performance metrices

```{r Analyse LOOCV metrics}
# Read the cv metrics
rk_cv_metrics <- read.csv("../RK_Monthly_Mean/rk_loocv_metrics.csv",
                       stringsAsFactors = FALSE)

# Prepare monthly date and tidy format
rk_cv_metrics_long <- rk_cv_metrics %>%
  mutate(
    month_date = as.Date(paste0(timestamp, "-01")),       # e.g. "2023-01" -> Date
    .keep = "all"
  ) %>%
  pivot_longer(
    cols = c(rk_cv_rmse, rk_cv_mae),
    names_to = "metric",
    values_to = "value"
  ) %>%
  arrange(month_date)

# Summer shading (JJA) – reuse if already defined
if (!exists("summer_start") || !exists("summer_end")) {
  yr <- year(min(lm_metrics_long$month_date, na.rm = TRUE))
  summer_start <- as.Date(sprintf("%d-06-01", yr))
  summer_end   <- as.Date(sprintf("%d-08-31", yr))
}

# Plot: Monthly Evaluation of the Regression-Kriging CV Metrics (RMSE & MAE)
p_cv <- ggplot(rk_cv_metrics_long,
               aes(x = month_date, y = value, color = metric, group = metric)) +
  annotate("rect", xmin = summer_start, xmax = summer_end,
           ymin = -Inf, ymax = Inf, alpha = 0.06, fill = "grey50") +
  geom_line(linewidth = 1.2) +
  geom_point(size = 1.8) +
  geom_hline(
    aes(yintercept = 0, linetype = "Perfect Prediction (Error = 0)")
  ) +
  scale_color_manual(
    values = c("rk_cv_rmse" = "#6699CC", "rk_cv_mae" = "#CC6677"),
    labels = c("rk_cv_rmse" = "Root Mean Square Error (RMSE)",
               "rk_cv_mae"  = "Mean Absolute Error (MAE)")
  ) +
  scale_linetype_manual(
    name   = "",
    values = c("Perfect Prediction (Error = 0)" = "dotted")
  ) +
  scale_x_date(date_breaks = "1 month", date_labels = "%Y-%m") +
  labs(
    title    = "Monthly Evaluation of the LOOCV Metrics for the Kriging Model",
    subtitle = "Monthly RMSE and MAE values from LOOCV of models predicting monthly mean temperature",
    x        = "Month",
    y        = "Error Metric [°C]",
    color    = "Metrics",
    caption = "LOOCV = leave-one-out cross-validation"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position  = "top",
    panel.grid.minor = element_blank(),
    axis.text.x      = element_text(angle = 45, hjust = 1)
  )

p_cv

# Save if needed
ggsave("../plots/cv_metrics_monthly_rmse_mae.png", plot = p_cv, width = 10, height = 6, dpi = 300)
```

```{r Analyse RK metrics}
# Read the rk metrics
rk_metrics <- read.csv("../RK_Monthly_Mean/rk_metrics.csv",
                       stringsAsFactors = FALSE)

# Prepare monthly date and tidy format
rk_metrics_long <- rk_metrics %>%
  mutate(
    month_date = as.Date(paste0(month, "-01")),  # "2023-01" -> Date
    .keep = "all"
  ) %>%
  pivot_longer(
    cols = c(rk_rmse, rk_mae),
    names_to = "metric",
    values_to = "value"
  ) %>%
  arrange(month_date)

# Monthly Evaluation of the RK Metrics (RMSE & MAE)
p_rk <- ggplot(rk_metrics_long,
               aes(x = month_date, y = value, color = metric, group = metric)) +
  annotate("rect", xmin = summer_start, xmax = summer_end,
           ymin = -Inf, ymax = Inf, alpha = 0.06, fill = "grey50") +
  geom_line(linewidth = 1.2) +
  geom_point(size = 1.8) +
  geom_hline(
    aes(yintercept = 0, linetype = "Perfect Prediction (Error = 0)")
  ) +
  scale_color_manual(
    values = c("rk_rmse" = "#6699CC", "rk_mae" = "#CC6677"),
    labels = c("rk_rmse" = "Root Mean Square Error (RMSE)",
               "rk_mae"  = "Mean Absolute Error (MAE)")
  ) +
  scale_linetype_manual(
    name   = "",
    values = c("Perfect Prediction (Error = 0)" = "dotted")
  ) +
  scale_x_date(date_breaks = "1 month", date_labels = "%Y-%m") +
  labs(
    title    = "Monthly Evaluation of Regression-Kriging Metrics",
    subtitle = "Monthly RMSE and MAE values from predictions evaluated at station locations",
    x        = "Month",
    y        = "Error Metric [°C]",
    color    = "Metrics"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position  = "top",
    panel.grid.minor = element_blank(),
    axis.text.x      = element_text(angle = 45, hjust = 1)
  )

p_rk

# Save if needed
ggsave("../plots/rk_metrics_monthly_rmse_mae.png", plot = p_rk, width = 10, height = 6, dpi = 300)
```

```{r Analyse MLR metrics}
# Read mlr metrics
lm_metrics <- read.csv("../RK_Monthly_Mean/lm_model_performance_summary.csv",
                       stringsAsFactors = FALSE)

# Create month_date (use month column; fallback to timestamp if needed)
lm_metrics <- lm_metrics %>%
  mutate(
    month_date =
      if ("month" %in% names(.)) {
        as.Date(paste0(month, "-01"))
      } else {
        as.Date(format(as.POSIXct(timestamp, origin = "1970-01-01", tz = "Europe/Berlin"),
                       "%Y-%m-01"))
      })

# Long format for R² metrics
lm_metrics_long <- lm_metrics %>%
  pivot_longer(
    cols = c(r_squared, adj_r_squared),
    names_to = "metric",
    values_to = "value"
  ) %>%
  arrange(month_date)

# Plot: Monthly LM performance (R² & Adjusted R²)
p_lm <- ggplot(lm_metrics_long,
               aes(x = month_date, y = value, color = metric, group = metric)) +
  annotate("rect", xmin = summer_start, xmax = summer_end,
           ymin = -Inf, ymax = Inf, alpha = 0.06, fill = "grey50") +
  geom_line(linewidth = 1.2) +
  geom_point(size = 1.8) +
  geom_hline(
    aes(yintercept = 1, linetype = "Perfect Fit (R² = 1)")
  ) +
  scale_color_manual(
    values = c("r_squared" = "#6699CC", "adj_r_squared" = "#CC6677"),
    labels = c("r_squared" = expression(R^2),
               "adj_r_squared" = expression(Adjusted~R^2))
  ) +
  scale_linetype_manual(
    name   = "",
    values = c("Perfect Fit (R² = 1)" = "dotted")
  ) +
  scale_x_date(date_breaks = "1 month", date_labels = "%Y-%m") +
  scale_y_continuous(limits = c(0, 1), expand = expansion(mult = c(0.01, 0.05))) +
  labs(
    title    = "Monthly Evaluation of Multiple Linear Regression Model Performance",
    subtitle = "Monthly R² and Adjusted R² from models predicting monthly mean temperature",
    x        = "Month",
    y        = "Metric Value",
    color    = "Metrics"
    ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position  = "top",
    panel.grid.minor = element_blank(),
    axis.text.x      = element_text(angle = 45, hjust = 1)
  )

p_lm

# Save if needed
ggsave("../plots/lm_metrics_monthly_r2.png", plot = p_lm, width = 10, height = 6, dpi = 300)

```
