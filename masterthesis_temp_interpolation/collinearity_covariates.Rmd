---
title: "collinearity_covariates"
author: "Johannes Gruenewald"
date: "2025-07-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load Required Libraries

# Spatial Data Handling & Processing
library(sf)
library(sp)
library(terra)
library(raster)
library(stars)
library(spdep)

# Spatial Analysis & Interpolation
library(gstat)
library(randomForest)
library(nlme)
library(automap)
library(mgcv)

# Data Manipulation & Wrangling
library(tidyverse)

# Data Visualization
library(ggplot2)
library(scales)
library(gridExtra)
library(corrplot)

# Mapping & Interactive Visualization
library(tmap)

# Additional
library(lattice)
library(car)
```

------------------------------------------------------------------------

```{r Load temp data}

# Complete data import and pre-processing of the temperature (July 2023)

# Read temperature data for the entire year of 2023
temp <- sf::read_sf('../data/temp_HD/sensor_data_20230107_31days.gpkg')

# Removes rows where temp is NA
temp <- temp %>% filter(!is.na(temperature))

# Reproject the data for Germany
temp <- st_transform(temp, crs="EPSG:32632")

# Clean the data from outliers -> currently working with hard, manual breaks
# Currently nothing is removed by this step because no measurements are above 40°C for the year 2023
temp_clean <- temp %>% filter(temperature >= -35, temperature <= 40)

# Drop all measurement stations which didn't collect data the entire year around
temp_clean_station <- temp_clean %>%
  mutate(dateobserved = as.POSIXct(dateobserved, tz = "Europe/Berlin")) %>%
  filter(!entity_id %in% c(
    "hd:DE_Heidelberg_69120_12:WeatherObserved",
    "hd:DE_Heidelberg_69120_34:WeatherObserved",
    "hd:DE_Heidelberg_69123_41:WeatherObserved",
    "hd:DE_Gaiberg_69251_21:WeatherObserved",
    "hd:DE_Heidelberg_46:WeatherObserved"
  ))

# Check if exactly 5 stations were dropped
cat("Number of stations BEFORE cleaning: ",
    length(unique(na.omit(temp_clean$entity_id))), "\n")

cat("Number of stations AFTER cleaning:  ",
    length(unique(na.omit(temp_clean_station$entity_id))), "\n")

# Calculate hourly mean temp for cleaned data
temp_clean_station_hm <- temp_clean_station %>%
    mutate(hour = floor_date(dateobserved, unit = "hour")) %>%   # round down
    group_by(entity_id, hour) %>%
    summarise(hm_temp = mean(temperature, na.rm = TRUE), .groups = "drop")
```

```{r Load and preprocess covariates}

# Import of pre-processed temp data and import and pre-processing of covariates 

#Shortcut -> import pre-processed hourly means
temp_clean_station_hm <- sf::read_sf('../data/temp_HD/temp_clean_station_hm.gpkg')

temp_clean_station_hm <- st_transform(temp_clean_station_hm, crs="EPSG:32632")

# Drop Gaiberg station as it is outside of AOI
temp_clean_station_hm <- temp_clean_station_hm %>%
  filter(!entity_id %in% c(
    "hd:DE_Gaiberg_69251_21:WeatherObserved"
  ))


# Import AOI and station coords
hd_bounds <- sf::read_sf('../data/AOI/OSM_boundaries_HD.geojson')
station_coords_sf <- sf::read_sf('../data/temp_HD/station_coords.gpkg')

# Import the covariates
dem <- terra::rast("../data/DEM/hd_elevation_4326.tif")
tch <- terra::rast("../data/canopy_height/hd_canopy_height_4326.tif")
ghs_bh <- terra::rast("../data/building_height/hd_building_height_4326.tif")

# Mask out all values which are assigned to water and have value 101
# Not part of this area. But needs to be masked as well: 102 Snow/ice; 103 No data
tch[tch == 101] <- NA

# Reproject the data
hd_bounds <- st_transform(hd_bounds, crs = st_crs(temp_clean_station_hm))
station_coords_sf <- st_transform(station_coords_sf, crs = st_crs(temp_clean_station_hm))
dem <- terra::project(dem, y = crs(temp_clean_station_hm))
tch <- terra::project(tch, y = crs(temp_clean_station_hm))
ghs_bh <- terra::project(ghs_bh, y = crs(temp_clean_station_hm))

# Check if any CRS mismatches
if (!identical(crs(tch), crs(dem))) {
  stop("CRS mismatch: Tree canopy height and DEM don't have the same CRS.")
}
if (!identical(crs(ghs_bh), crs(dem))) {
  stop("CRS mismatch: Building height and DEM don't have the same CRS.")
}
cat("All covariates share the same CRS.\n")

# Convert to SpatialPointsDataFrame
station_coords <- as(station_coords_sf, "Spatial")

# Create a Raster Stack for all covariate information
cat("Checking input raster resolutions in metres:\n")
cat(sprintf("DEM:    %.2f x %.2f\n", terra::res(dem)[1], terra::res(dem)[2]))
cat(sprintf("TCH:    %.2f x %.2f\n", terra::res(tch)[1], terra::res(tch)[2]))
cat(sprintf("GHS_BH: %.2f x %.2f\n\n", terra::res(ghs_bh)[1], terra::res(ghs_bh)[2]))

# Align canopy height and building height to DEM resolution and extent
tch_aligned    <- terra::resample(tch, dem, method = "bilinear")
ghs_bh_aligned <- terra::resample(ghs_bh, dem, method = "near")

# Check alignment after resampling
if (!terra::compareGeom(dem, tch_aligned, ghs_bh_aligned, stopOnError = FALSE)) {
  stop("Covariate rasters are not perfectly aligned after resampling. Check extent/resolution/CRS.")
}

# Combine layers into a single SpatRaster stack
env_stack <- c(dem, tch_aligned, ghs_bh_aligned)

# Rename layers for clarity
names(env_stack) <- c("elevation", "canopy_height", "building_height")

# Code to include lat and lon information in raster stack

# Also add lat and lon to the raster stack
# Create coordinate rasters
lon <- terra::xFromCell(env_stack, 1:ncell(env_stack))
lat <- terra::yFromCell(env_stack, 1:ncell(env_stack))

# Convert to raster layers
lon_raster <- dem
lat_raster <- dem
values(lon_raster) <- lon
values(lat_raster) <- lat
names(lon_raster) <- "lon"
names(lat_raster) <- "lat"

# Stack the three raster layers
grids <- c(env_stack, lon_raster, lat_raster)

# Preparation of grid as a covariate for running RK
grids_ras <- stack(grids)

# Convert to SpatialGridDataFrame
grids_sp <- as(grids_ras, "SpatialGridDataFrame")
```

------------------------------------------------------------------------

Calculate correlation between the three covariates
Because covariates are not normally distributed use Spearman’s rank correlation

```{r Calculate correlation between the three covariates}

# Distribution of the covariates
par(mfrow = c(1,3))
terra::hist(grids$elevation,       main = "Elevation",       xlab = "m")
terra::hist(grids$canopy_height,   main = "Canopy height",   xlab = "m")
terra::hist(grids$building_height, main = "Building height", xlab = "m")
par(mfrow = c(1,1))

# Convert Spatial object into plain data.frame
covariates_df <- as.data.frame(grids_sp)  

# Correlations Spearman and Pearson
corr_s <- cor(covariates_df[c("elevation","canopy_height","building_height")],
              use="pairwise.complete.obs", method="spearman")
corr_p <- cor(covariates_df[c("elevation","canopy_height","building_height")],
              use="pairwise.complete.obs", method="pearson")

# Visualize correlation matrix as color heatmap
png("../plots/correlation_covariates_spearman.png", width = 2000, height = 1600, res = 300)
corrplot_s <- corrplot(corr_s, method = "color", 
                       addCoef.col = "black", tl.col = "black", tl.srt = 45,number.cex = 0.8)
dev.off()

png("../plots/correlation_covariates_pearson.png", width = 2000, height = 1600, res = 300)
corrplot_p <- corrplot(corr_p, method = "color", 
                       addCoef.col = "black", tl.col = "black", tl.srt = 45, number.cex = 0.8)
dev.off()
```

The results fit really well to Heidelberg and its surroundings and describe how they look like.

-	Elevation vs. Canopy (r ≈ 0.83): Strong positive correlation — higher hills (e.g., Heiligenberg, Königstuhl) tend to have taller/denser canopy.
-	Elevation vs. Building height (r ≈ −0.34): Moderate negative correlation — taller buildings are concentrated at lower elevations (valley floor).
-	Canopy vs. Building height (r ≈ −0.36): Moderate negative correlation — built-up areas generally coincide with less canopy, and vice versa (they tend not to co-occur).

--------------------------------------------------




------------------------------------------------------------------------

```{r Adding covariates to temperature data}

# Convert Spatial object to RasterBrick -> SpatRaster
r_brick   <- brick(grids_sp)
grid_terra <- rast(r_brick)

# Extract raster values at point features
ex <- terra::extract(grid_terra, temp_clean_station_hm)

# Aggregate duplicates to a single row per original feature
# Use mean
ex_agg <- aggregate(. ~ ID, data = ex, FUN = mean, na.rm = TRUE)

# Reorder aggregated rows to match original feature order
ex_agg <- ex_agg[match(seq_len(nrow(temp_clean_station_hm)), ex_agg$ID), -1]

# Bind attributes + extracted covariates
temp_clean_station_hm_cov <- cbind(as.data.frame(temp_clean_station_hm), ex_agg)

str(temp_clean_station_hm_cov)
```

Z-score normalization: mean of 0 and standard deviation of 1

```{r}
covars <- c("elevation", "canopy_height", "building_height")   # add "lon","lat" if you want

# learn mean/sd
mu  <- sapply(temp_clean_station_hm_cov[, covars], function(x) mean(x, na.rm = TRUE))
sdv <- sapply(temp_clean_station_hm_cov[, covars], function(x) sd(x,   na.rm = TRUE))

# guard against zero-variance columns
zero_sd <- sdv == 0 | is.na(sdv)
if (any(zero_sd)) {
  warning("Zero-variance covariate(s) set to 0: ",
          paste(names(sdv)[zero_sd], collapse = ", "))
  sdv[zero_sd] <- 1
}

# add *_z columns
for (nm in covars) {
  temp_clean_station_hm_cov[[paste0(nm, "_z")]] <-
    (temp_clean_station_hm_cov[[nm]] - mu[[nm]]) / sdv[[nm]]
}

# (optional) keep the parameters for reproducibility
z_params <- data.frame(covariate = names(mu), mean = as.numeric(mu), sd = as.numeric(sdv))
```

```{r}
# long format for faceting
df_long <- temp_clean_station_hm_cov %>%
  select(all_of(covars)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "value") %>%
  filter(!is.na(value))

# histograms
p_cov <- ggplot(df_long, aes(x = value)) +
  geom_histogram(bins = 40, alpha = 0.85) +
  facet_wrap(~ variable, scales = "free", ncol = 1) +
  labs(
    title = "Distributions of Covariates",
    x = NULL, y = "Count"
  ) +
  theme_minimal(base_size = 13) +
  theme(panel.grid.minor = element_blank())

p_cov
```


------------------------------------------------------------------------

Calculate correlation between the three covariates and the dependent variable temperature using a linear regression model

```{r Calculate correlation between the three covariates and the dependent variable temperature}

# Pick relevant columns
df <- temp_clean_station_hm_cov %>%
  st_drop_geometry() %>%   # remove geometry column
  dplyr::select(entity_id, hm_temp, elevation, canopy_height, building_height)

# Aggregate temperature per station (mean across time)
station_df <- df %>%
  group_by(entity_id, elevation, canopy_height, building_height) %>%
  summarise(mean_temp = mean(hm_temp, na.rm = TRUE), .groups = "drop")

# Compute correlation matrix (Pearson + Spearman)
vars <- c("mean_temp", "elevation", "canopy_height", "building_height")

corr_p <- cor(station_df[vars], use = "pairwise.complete.obs", method = "pearson")
corr_s <- cor(station_df[vars], use = "pairwise.complete.obs", method = "spearman")

print("Pearson correlation:")
print(corr_p)

print("Spearman correlation:")
print(corr_s)

# reshape to long format
station_long <- station_df %>%
  pivot_longer(cols = c(elevation, canopy_height, building_height),
               names_to = "covariate", values_to = "value")

# 2. Compute Pearson correlation per covariate
cors <- station_long %>%
  group_by(covariate) %>%
  summarise(
    r = cor(value, mean_temp, method = "pearson", use = "pairwise.complete.obs")
  ) %>%
  mutate(
    label = sprintf("italic(r) == %.2f", r)   # format for plotmath
  )

p_corr_temp_cov <- ggplot(station_long, aes(x = value, y = mean_temp)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, color = "darkred") +
  #geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), color = "blue", linetype = "dashed")
  facet_wrap(~ covariate, scales = "free_x", nrow = 1,
             labeller = labeller(
               covariate = c(elevation = "Elevation [m]",
                             canopy_height = "Canopy Height [m]",
                             building_height = "Building Height [m]")
             )) +
  geom_text(
    data = cors,
    aes(label = label),
    x = -Inf, y = Inf,
    hjust = -0.2, vjust = 2,
    parse = TRUE,
    size = 5,
    fontface = "bold",
    inherit.aes = FALSE
  ) +
  scale_y_continuous(limits = c(9, 15)) +
  scale_x_continuous(expand = expansion(mult = c(0.02, 0.02))) +
  labs(title = "Linear Relationships Between Yearly Mean Temperature and Environmental Covariates",
       x = NULL, y = "Yearly Mean Temperature [°C]") +
  theme_bw() +
  theme(
    strip.text = element_text(face = "bold", size = 14),
    plot.title = element_text(
        face = "bold", size = 20, hjust = 0.5,
        margin = margin(t = 10, b = 10)),
    axis.title.y = element_text(size = 14),
    axis.text = element_text(size = 12)
  )

p_corr_temp_cov

# Save output to file
ggsave("../plots/correlation_temperature_vs_covariates.png", p_corr_temp_cov, width = 12, height = 6, dpi = 300)
```

------------------------------------------------------------------------

Calculate correlation between the three covariates and the dependent variable temperature using a GAM model

```{r}
p_corr_temp_cov_gam <- ggplot(station_long, aes(x = value, y = mean_temp)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "gam", formula = y ~ s(x, k = 5), 
              se = TRUE, color = "darkblue") +
  facet_wrap(~ covariate, scales = "free_x", nrow = 1,
             labeller = labeller(
               covariate = c(elevation = "Elevation [m]",
                             canopy_height = "Canopy Height [m]",
                             building_height = "Building Height [m]")
             )) +
  scale_y_continuous(limits = c(9, 15)) +
  labs(title = "Yearly Mean Temperature per Station vs Environmental Covariates (GAM fit)",
       x = NULL, y = "Mean Temperature [°C]") +
  theme_bw() +
  theme(strip.text = element_text(face = "bold"))

p_corr_temp_cov_gam
```

------------------------------------------------------------------------

Comparison between linear and non-linear model

```{r}
# Elevation
lm(mean_temp ~ elevation, data = station_df)
gam(mean_temp ~ s(elevation, k = 5), data = station_df)

# Building height
lm(mean_temp ~ building_height, data = station_df)
gam(mean_temp ~ s(building_height, k = 5), data = station_df)

# Canopy height
lm(mean_temp ~ canopy_height, data = station_df)
gam(mean_temp ~ s(canopy_height, k = 5), data = station_df)
```

------------------------------------------------------------------------

Multicollinearity

Test for simple Linear Regression Model

In regression analysis, multicollinearity occurs when two or more predictor variables are highly correlated with each other, such that they do not provide unique or independent information in the regression model.

If the degree of correlation is high enough between predictor variables, it can cause problems when fitting and interpreting the regression model. 

The most straightforward way to detect multicollinearity in a regression model is by calculating a metric known as the variance inflation factor, often abbreviated VIF.

VIF measures the strength of correlation between predictor variables in a model. It takes on a value between 1 and positive infinity.

We use the following rules of thumb for interpreting VIF values:

- VIF = 1: There is no correlation between a given predictor variable and any other predictor variables in the model.
- VIF between 1 and 5: There is moderate correlation between a given predictor variable and other predictor variables in the model.
- VIF > 5: There is severe correlation between a given predictor variable and other predictor variables in the model.

Source: https://www.statology.org/multicollinearity-in-r/

```{r Check for multicollineraity}

#define multiple linear regression model
mlr_coll <- lm(hm_temp ~ elevation + canopy_height + building_height, data = temp_clean_station_hm_cov)

mlr_coll

vif_df <- car::vif(mlr_coll) %>%
  as.data.frame() %>%
  tibble::rownames_to_column("covariate") %>%
  rename(VIF = 2)

# Plot VIF values
p_vif <- ggplot(vif_df, aes(x = covariate, y = VIF, fill = covariate)) +
  geom_col(color = "grey30", linewidth = 0.3) +
  scale_fill_manual(
    values = c(
      "building_height" = "darkorange3",
      "canopy_height"   = "darkolivegreen",
      "elevation"       = "burlywood2"
    ),
    guide = "none"
  ) +
  scale_x_discrete(
    labels = c(
      "building_height" = "Building Height",
      "canopy_height"   = "Canopy Height",
      "elevation"       = "Elevation"
    )
  ) +
  geom_hline(yintercept = 5,  linetype = "dashed", color = "black", linewidth = 0.8) +
  annotate("text", x = 0.5, y = 5.2,
         label = "VIF > 5 high multicollinearity",
         hjust = 0, size = 4, color = "grey40") +
  geom_text(aes(label = round(VIF, 2)),
          vjust = -0.5, size = 5) +
  labs(
    title = "Variance Inflation Factors (VIF) for Model Covariates",
    caption = "Values assess multicollinearity among predictors",
    x = "Covariate",
    y = "VIF"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", size = 20, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5, color = "grey40"),
    plot.caption.position = "plot",
    plot.caption = element_text(hjust = 0, margin = margin(t = 20)),
    axis.text.x = element_text(angle = 30, hjust = 1),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(color = "grey85")
  )

p_vif

# Save output to file
ggsave("../plots/multicollinearity.png", p_vif, width = 8, height = 5, dpi = 300)
```

None of the predictors (elevation, canopy height, building height) show problematic multicollinearity. All VIFs are under 5, suggesting the model is stable with respect to predictor relationships.

------------------------------------------------------------------------



------------------------------------------------------------------------

GAM for all three covariates

Comment: A general rule of thumb is to use a high number of splines and use cross-validation of lambda (λ) values to find the model that generalises best. Remember we can have different splines and lambda values for every variable in our model.

```{r}
gam_all <- gam(mh_temp ~ 
                  s(elev) + 
                  s(canopy) + 
                  s(bldg), 
                data = temp_shm.ex)
summary(gam_all)

concurvity(gam_all, full = TRUE)
```



Example: Visualize the results

```{r}
# Vary elevation across its range; fix the others at their median
predict_temp <- data.frame(
  elevation = seq(min(temp_shm.ex$elev), max(temp_shm.ex$elev), length.out = 20),
  tree_canopy_height = median(temp_shm.ex$canopy),
  building_height = median(temp_shm.ex$bldg)
)

# Predict using the full GAM model
predictions <- predict(gam_all, newdata = predict_temp, type = "response", se.fit = TRUE)

# Plot the data and the GAM fit
ggplot() +
  geom_point(data = temp_shm.ex, aes(x = elevation, y = mh_temp)) +
  geom_line(data = data.frame(elevation = predict_temp$elevation, mh_temp = predictions$fit), 
            aes(x = elevation, y = mh_temp), color = "blue", size = 1) +
  geom_ribbon(data = data.frame(elevation = predict_temp$elevation, fit = predictions$fit, 
                                se = predictions$se.fit), aes(x = elevation, 
                                ymin = fit - 1.96 * se, 
                                ymax = fit + 1.96 * se), alpha = 0.3) +
  labs(title = "GAM Fit for Monthly Mean Temperature vs. Elevation", 
       x = "Elevation [m]", y = "Monthly Mean Temperature [°C]") +
  theme_minimal()
```
