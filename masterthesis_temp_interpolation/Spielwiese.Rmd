---
title: "Spielwiese"
output: html_document
date: "2025-12-05"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Old version: Extract values from all the raster and add to temperature data at point locations

```{r}
# Extract raster values at the temp locations
elevation_values <- terra::extract(dem, temp_dm)

# Extract raster values at the temp locations
building_height_values <- terra::extract(ghs_bh, temp_dm)

# Extract tree canopy height values at the temp locations
canopy_heigth_values <- terra::extract(tch, temp_dm)

# Use dplyr to add the extracted values as a new column in the sf object
temp_dm <- temp_dm %>%
  mutate(elevation = elevation_values[[2]])

# Use dplyr to add the extracted values as a new column in the sf object
temp_dm <- temp_dm %>%
  mutate(building_height = building_height_values[[2]])

# Use dplyr to add the extracted values as a new column in the sf object
temp_dm <- temp_dm %>%
  mutate(tree_canopy_height = canopy_heigth_values[[2]])

# Check the updated sf object
print(temp_dm)
```

--------------------------------------------------------------------------------

Test Random Forest (RF) instead of regression models to model complex relationships and see if the performance is similar to flexible regression models.

Splitting the data in train and test data

```{r}
nrow(temp_dm)

# Splitting data in train and test data
split_dm <- sample.split(temp_dm$daily_mean_temperature, SplitRatio = 0.7)
length(split_dm)

train_dm <- subset(temp_dm, split_dm == "TRUE")
test_dm <- subset(temp_dm, split_dm == "FALSE")
```

Fit the Random Forest Model

```{r}
#make this example reproducible
set.seed(10)

#fit the random forest model
rf_model_dm <- randomForest(
  formula = daily_mean_temperature ~ elevation + tree_canopy_height + building_height,
  data = train_dm,
  mtry = 3,
  importance = TRUE,
  na.action = na.omit
)

rf_model_dm
importance(rf_model_dm)

#find number of trees that produce lowest test MSE
which.min(rf_model_dm$mse)

#find RMSE of best model
sqrt(rf_model_dm$mse[which.min(rf_model_dm$mse)]) 

#plot the test MSE by number of trees
plot(rf_model_dm)

#Importance plot
importance(rf_model_dm)

#produce variable importance plot
varImpPlot(rf_model_dm) 
```

Tune the model
This function produces the following plot, which displays the number of predictors used at each split when building the trees on the x-axis and the out-of-bag estimated error on the y-axis:

```{r}
model_tuned_dm <- tuneRF(
  x = data.frame(
    elevation = train_dm$elevation,
    building_height = train_dm$building_height,
    tree_canopy_height = train_dm$tree_canopy_height
  ),
  y = train_dm$daily_mean_temperature,  # define response variable
  ntreeTry = 500,
  mtryStart = 3,
  stepFactor = 1.5,
  improve = 0.01,
  trace = FALSE  # don't show real-time progress
)
```

We can see that the lowest OOB error is achieved by using 3 randomly chosen predictors at each split when building the trees.

Use the Final Model to Make Predictions and derive Residuals

```{r}
# Predict on training data
predicted_dm_rf <- predict(rf_model_dm, newdata=test_dm)

# Calculate residuals: observed - predicted
residuals_dm_rf <- temp_dm$daily_mean_temperature - predicted_dm_rf

plot(residuals_dm_rf)
```

--------------------------------------------------------------------------------

Histogram to check data distribution

```{r}
# Set up a 1-row, 3-column plotting area
par(mfrow = c(1, 3))

# Plot the histograms
hist(july_mean_temp$elevation, main = "Elevation", xlab = "Elevation (m)", col = "lightblue")
hist(july_mean_temp$tree_canopy_height, main = "Tree Canopy Height", xlab = "Height (m)", col = "lightgreen")
hist(july_mean_temp$building_height, main = "Building Height", xlab = "Height (m)", col = "lightcoral")
```

log-transformed the data to check possible changes to distribution

```{r}
# Set up a 1-row, 3-column plotting area
par(mfrow = c(1, 3))

# Plot the log-transformed histograms
hist(log(july_mean_temp$elevation + 1), 
     main = "Log(Elevation + 1)", 
     xlab = "log(Elevation)", 
     col = "lightblue")

hist(log(july_mean_temp$tree_canopy_height + 1), 
     main = "Log(Tree Canopy Height + 1)", 
     xlab = "log(Height)", 
     col = "lightgreen")

hist(log(july_mean_temp$building_height + 1), 
     main = "Log(Building Height + 1)", 
     xlab = "log(Height)", 
     col = "lightcoral")
```

--------------------------------------------------------------------------------

!!Try regression models!!

Stepwise MLR

```{r}
# stepwise variable selection
model.MLR.step <- step(model, direction="both")

# summary of the new model using stepwise covariates selection
summary(model.MLR.step)

install.packages("gtsummary")

model.MLR.step |> tbl_regression()
```

Interpretation of MLR performance

```{r}
# graphical diagnosis of the regression analysis
par(mfrow=c(2,2))
plot(model.MLR.step)
par(mfrow=c(1,1))
```

--------------------------------------------------------------------------------

GLS model

```{r}
# Extract coordinates (assuming `geom` is the column with spatial data)
july_mean_temp$coords <- st_coordinates(july_mean_temp$geom)

# Separate the coordinates into `x` and `y` columns
july_mean_temp$x <- july_mean_temp$coords[, 1]
july_mean_temp$y <- july_mean_temp$coords[, 2]

gls_model <- gls(mean_temperature ~ elevation + tree_canopy_height + building_height,
                 data = july_mean_temp,
                 correlation = corExp(form = ~ x + y, nugget = TRUE))

summary(gls_model)
```

--------------------------------------------------------------------------------

Test RF instead of regression model to model complex relationships and see if the performance is similar

Try RF

```{r}
# 2. Fit Random Forest model
rf_model <- randomForest(
  mean_temperature ~ elevation + tree_canopy_height + building_height,
  data = july_mean_temp,
  ntree = 500,
  importance = TRUE,
  na.action = na.omit
)

# View basic model summary
print(rf_model)

# View variable importance
importance(rf_model)
varImpPlot(rf_model)
```

```{r}
# 3. Predict and calculate residuals
july_mean_temp$rf_pred <- predict(rf_model)
july_mean_temp$residuals <- july_mean_temp$mean_temperature - july_mean_temp$rf_pred
```

```{r}
# 4. Fit variogram to residuals
fitted <- autofitVariogram(residuals ~ 1, input_data = july_mean_temp)
fitted_vgm <- fitted$var_model
plot(fitted$exp_var, fitted$var_model)
```

Create prediction locations for the kriging process including the covariates

```{r}
# Convert raster to points, including values, and remove NAs
predLocations <- terra::as.points(dem, values=TRUE, na.rm=TRUE)

# Reproject the elevation data to match correct CRS
predLocations <- terra::project(predLocations, y = crs(july_mean_temp))

# Check CRS of locations
crs(predLocations)

# Convert the points to a SpatialPointsDataFrame
predLocations <- as(predLocations, "Spatial")

# Convert sf object to sp object
july_mean_temp_sp <- as(july_mean_temp, "Spatial")

# Set CRS of predLocations_sp to match july_mean_temp
sp::proj4string(predLocations) == sp::proj4string(july_mean_temp_sp)

# Display the updated gridded points
class(predLocations)
```

```{r}
# 6. Interpolate residuals by kriging
kriged_resid <- krige(residuals ~ 1,
                      loc = july_mean_temp_sp,
                      newdata = predLocations,
                      model = fitted_vgm)
```

```{r}
# 10. Model performance metrics on training data
obs <- july_mean_temp$mean_temperature
pred_rf <- july_mean_temp$rf_pred
resid <- july_mean_temp$residuals

# R², RMSE, MAE
r2_rf <- 1 - sum((obs - pred_rf)^2) / sum((obs - mean(obs))^2)
rmse_rf <- sqrt(mean((obs - pred_rf)^2))
mae_rf <- mean(abs(obs - pred_rf))

cat("Random Forest Performance:\n")
cat("R² =", round(r2_rf, 3), "\n")
cat("RMSE =", round(rmse_rf, 3), "\n")
cat("MAE =", round(mae_rf, 3), "\n\n")

# 11. Moran's I on residuals (check spatial autocorrelation)
coords_mat <- coordinates(july_mean_temp_sp)
nb <- knn2nb(knearneigh(coords_mat, k = 4))
lw <- nb2listw(nb)
moran_result <- moran.test(resid, lw)
print(moran_result)

# 12. Cross-validation of kriging residuals
kr_cv <- krige.cv(residuals ~ 1, locations = july_mean_temp_sp, model = fitted_vgm)
cat("Kriging Cross-Validation:\n")
summary(kr_cv$residual)
```

