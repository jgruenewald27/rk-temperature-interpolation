---
title: "Test_RK_for_different_timestamps"
author: "Johannes Gruenewald"
date: "2024-11-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Load Required Libraries}

# Spatial Data Handling & Processing
library(sf)
library(sp)
library(terra)
library(raster)
library(stars)
library(spdep)

# Spatial Analysis & Interpolation
library(gstat)
library(randomForest)
library(nlme)
library(automap)
library(mgcv)

# Data Manipulation & Wrangling
library(tidyverse)

# Data Visualization
library(ggplot2)
library(scales)
library(gridExtra)

# Mapping & Interactive Visualization
#library(tmap)

# Additional
library(lattice)
```

--------------------------------------------------------------------------------

```{r Load and preprocess temp data}

# Read temperature data
temp <- sf::read_sf('../data/temp_HD/sensor_data_20230107_31days.gpkg')

# Removes rows where temp is NA
temp <- temp[!is.na(temp$temperature), ] 

# Reproject the data for Germany
temp <- st_transform(temp, crs="EPSG:32632")

# Ensure dateobserved is in the correct date-time format with German timezone
temp <- temp %>%
  mutate(dateobserved = as.POSIXct(dateobserved, format="%Y-%m-%d %H:%M:%S", tz = "Europe/Berlin"))

# Calculate hour count since epoch, rounded down to current hour
temp$chour <- floor(as.numeric(temp$dateobserved) / 3600)

# Test the results
print(format(as.POSIXct(temp$chour[66163] * 3600, origin = "1970-01-01", tz = "Europe/Berlin"), "%Y-%m-%d %H:%M:%S %Z"))
```

--------------------------------------------------------------------------------

```{r Calculate hourly means for each unique stations for the month of July}

# Calculate mean temperature for each station and hour during July
temp_hm <- temp %>%
  filter(format(dateobserved, "%m") == "07") %>%  # Keep only July data
  group_by(stationname, chour) %>%                # Group by station and hour
  summarise(mh_temp = mean(temperature, na.rm = TRUE), .groups = "drop") %>%
  mutate(hour = as.POSIXct(chour * 3600, origin = "1970-01-01", tz = "Europe/Berlin"))
```

--------------------------------------------------------------------------------

```{r Load the elevation data}

dem <- terra::rast("../data/DEM/hd_elevation_4326.tif")

# Reproject the elevation data to match correct CRS
dem <- terra::project(dem, y = crs(temp))
```

```{r Load the tree canopy height data}

tch <- terra::rast("../data/Canopy_height/clip_Forest_height_2019_NAFR.tif")

# Mask out all values which are assigned to water and have value 101
# Not part of this area. But needs to be masked as well: 102 Snow/ice; 103 No data
tch[tch == 101] <- NA

# Reproject the canopy height data to match correct CRS
tch <- terra::project(tch, y = crs(temp))

# Check if the two covariates have the same crs
crs(tch) == crs(dem)
```

```{r Load the building height data}

ghs_bh <- terra::rast("../data/building_height/clip_GHS_BUILT_H_AGBH_E2018_GLOBE_R2023A_54009_100_V1_0_R4_C19.tif")

# Reproject the building height data to match correct CRS
ghs_bh <- terra::project(ghs_bh, y = crs(temp))

# Check if CRS is correct
crs(ghs_bh) == crs(dem)
```

```{r}
# Create a Raster Stack for all the covariate information

# Check resolution of each raster
terra::res(dem)
terra::res(tch)
terra::res(ghs_bh)

# Align TCH and building height to DEM resolution and extent
tch_aligned    <- terra::resample(tch, dem, method = "bilinear")
ghs_bh_aligned <- terra::resample(ghs_bh, dem, method = "near")

# Stack all layers
env_stack <- c(dem, tch_aligned, ghs_bh_aligned)

# Rename layers for clarity
names(env_stack) <- c("elev", "canopy", "bldg")

env_stack
```

```{r}
# Also add lat and lon to the raster stack

# Create coordinate rasters
lon <- terra::xFromCell(env_stack, 1:ncell(env_stack))
lat <- terra::yFromCell(env_stack, 1:ncell(env_stack))

# Convert to raster layers
lon_raster <- dem
lat_raster <- dem
values(lon_raster) <- lon
values(lat_raster) <- lat
names(lon_raster) <- "lon"
names(lat_raster) <- "lat"
```

```{r}
# Stack the three raster layers
grids <- c(env_stack, lon_raster, lat_raster)

grids

# Conversion when running the analysis without proximity to water
# Preparation of grid as a covariate for running RK

# Convert SpatRaster to RasterLayer (raster package)
grids_ras <- stack(grids)

# Now convert to SpatialGridDataFrame
grids_sp <- as(grids_ras, "SpatialGridDataFrame") 

grids_sp@data
```

--------------------------------------------------------------------------------

Extract coordinates of the measurement stations

```{r}
# Extract coordinates of the measurement stations
# maybe use them as covariates

# Extract coordinates and data into a data frame
coords <- st_coordinates(temp)
locs <- cbind(temp, coords)
locs <- as.data.frame(locs)

# Keep only one row per station and select relevant columns
station_coords <- locs %>%
  distinct(stationname, .keep_all = TRUE) %>%
  select(stationname, X, Y)

coordinates(station_coords) <- ~ X + Y
proj4string(station_coords) <- CRS(proj4string(grids_sp))
```

--------------------------------------------------------------------------------

TEST IF LOOP WORKS

```{r create_output_folder}
output_dir <- "../RK_Results"
if (!dir.exists(output_dir)) dir.create(output_dir)
```

```{r main_loop}
# ================================================
# Loop through 24 hourly timestamps in `temp_hm`
# ================================================

# Get unique timestamps
timestamps <- unique(temp_hm$chour)[1:3]  # Test with first 3 unique chour timestamps

# Loop through each timestamp
total_metrics <- data.frame()
all_temp_data <- data.frame()


for (ts in timestamps) {
  cat("\n\n=====================\nProcessing timestamp:", ts, "\n=====================\n")

  # ------------------------------------------------
  # STEP 1: Filter hourly data and plot temperature
  # ------------------------------------------------
  
  # Select temperature data for the current hour
  sel_temp_hm <- temp_hm %>%
    filter(chour == ts)
  
  # Skip if fewer than 20 data points for current hour
  if (nrow(sel_temp_hm) < 20) next
  
  # Append the selected temperature data to full dataset
  all_temp_data <- rbind(all_temp_data, sel_temp_hm)
  
  # Generate line plot showing hourly mean temperature for each station
  # across the time range covered so far in the loop
  ggplot(all_temp_data, aes(x = hour, y = mh_temp, color = stationname, group = stationname)) +
    geom_line() +
    geom_point(size = 1) +
    labs(title = "Hourly Mean Temperature at Each Station",
         x = "Timestamp", y = "Mean Temperature (°C)", color = "Station") +
    theme_minimal(base_size = 12) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Save the temperature plot
  ggsave(file.path(output_dir, "all_stations_hourly_mean_temperature.png"),
       width = 10, height = 6, dpi = 300)

  # ------------------------------------------------
  # STEP 2: Add covariates (elev, canopy, bldg) from grid
  # ------------------------------------------------
  
  # Convert Spatial object to RasterBrick
  r_brick <- brick(grids_sp)
  
  # Convert RasterBrick to terra SpatRaster object
  grid_terra <- rast(r_brick)
  
  # Extract raster values at the point locations
  extracted_vals <- terra::extract(grid_terra, sel_temp_hm)
  
  # Remove the first column (ID)
  extracted_vals <- extracted_vals[,-1]
  
  # Combine the point data with the extracted raster values
  temp_shm.ex <- cbind(as.data.frame(sel_temp_hm), extracted_vals)
  
  # ------------------------------------------------
  # STEP 3: Fit linear model and prepare spatial data
  # ------------------------------------------------
  
  # Fit linear model
  lm.temp_shm <- lm(mh_temp ~ elev + canopy + bldg, data = temp_shm.ex)
  summary_lm <- summary(lm.temp_shm)
  
  # Extract model metrics
  model_metrics <- data.frame(
    timestamp     = ts,
    r_squared     = summary_lm$r.squared,
    adj_r_squared = summary_lm$adj.r.squared,
    f_statistic   = summary_lm$fstatistic[1],
    df1           = summary_lm$fstatistic[2],
    df2           = summary_lm$fstatistic[3],
    residual_se   = summary_lm$sigma
  )
  
  # Append to tracking data frame
  if (!exists("lm_metrics_all")) {
    lm_metrics_all <- model_metrics
  } else {
    lm_metrics_all <- rbind(lm_metrics_all, model_metrics)
  }

  # Save model's residuals back into original df as new column
  temp_shm.ex$residuals <- lm.temp_shm$residuals
  
  # Convert df into spatial object using existing geometry
  temp_shm.sf <- st_as_sf(temp_shm.ex)
  
  # ------------------------------------------------
  # STEP 4: Compute anisotropy & fit directional variogram
  # ------------------------------------------------
  
  # Compute empirical variogram map of model residuals
  # This helps visualize spatial autocorrelation in all directions
  varmap <- variogram(residuals ~ 1, data = temp_shm.sf, map = TRUE,
                    # cutoff is half the spatial extent (or diameter) of the study area
                    cutoff = sqrt(areaSpatialGrid(grids_sp)) / 2, 
                    # scaled relative to the resolution of the grid
                    width = 30 * grids_sp@grid@cellsize[1])

  # Store cutoff and bin width values for reuse and labeling
  cutoff_val <- sqrt(areaSpatialGrid(grids_sp)) / 2
  width_val  <- 30 * grids_sp@grid@cellsize[1]
  
  # Report how many rows are in variogram map
  cat("Variogram map has", nrow(as.data.frame(varmap)), "rows\n")
  
  # Define output filename for the variogram map plot
  file_varmap <- file.path(output_dir, paste0(ts, "_variogram_map.png"))
  
  # Plot and save the directional variogram map
  png(file_varmap, width = 8, height = 6, units = "in", res = 300)
  print(
    plot(varmap,
         col.regions = grey(rev(seq(0, 1, 0.025))),
         main = sprintf("Directional Variogram Map (cutoff: %.1f km, width: %.1f km)", 
                        cutoff_val / 1000, width_val / 1000)) # label in km
  )
  dev.off()
  
  # Compute directional variograms for North–South (0°) and East–West (90°)
  rv.temp <- variogram(residuals ~ 1, temp_shm.sf, alpha=c(0,90))
  
  # Fit theoretical exponential variogram model to the directional variograms
  rvgm.temp <- fit.variogram(rv.temp,
      vgm(psill=var(temp_shm.sf$residuals),
          "Exp", nugget=0, anis= c(p=90, s=0.5))) # p = direction, s = anisotropy ratio
  
  # Define output filename for directional variogram fit plot
  file_varfit <- file.path(output_dir, paste0(ts, "_directional_variogram_fit.png"))
  
  # Plot the empirical and fitted directional variograms and save
  png(file_varfit, width = 8, height = 6, units = "in", res = 300)
  print(
    plot(rv.temp, rvgm.temp,
         main = "Directional Variogram Fit (0° vs 90°)",
         plot.nu = FALSE, cex = 2, pch = "+", col = "black")
  )
  dev.off()
  
  # ------------------------------------------------
  # STEP 5: Cross-validation of residual kriging model
  # ------------------------------------------------

  # Perform leave-one-out cross-validation (LOOCV) of the kriging model
  cv_resid <- krige.cv(residuals ~ 1,
                       locations = temp_shm.sf,
                       model = rvgm.temp,
                       nfold = nrow(temp_shm.sf),   # one fold per observation = LOOCV
                       nmax = 10)                   # max number of neighbors used for prediction
  
  # Compute CV metrics
  cv_rmse <- sqrt(mean(cv_resid$residual^2))
  cv_mae  <- mean(abs(cv_resid$residual))
  cv_me   <- mean(cv_resid$residual)
  
  cat("CV RMSE:", round(cv_rmse, 2), "\n")
  cat("CV MAE :", round(cv_mae, 2), "\n")
  cat("CV Bias:", round(cv_me, 2), "\n")
  
  # Create df with CV metrics for current timestamp
  cv_metrics <- data.frame(
    timestamp = ts,
    cv_rmse   = cv_rmse,
    cv_mae    = cv_mae,
    cv_bias   = cv_me
  )
  
  # Append metrics to tracking df across all time steps
  if (!exists("cv_metrics_all")) {
    cv_metrics_all <- cv_metrics
  } else {
    cv_metrics_all <- rbind(cv_metrics_all, cv_metrics)
  }
  
  # Create and save scatterplot of predicted vs residual values from CV
  p_cv <- ggplot(cv_resid, aes(x = var1.pred, y = residual)) +
    geom_point() +
    geom_hline(yintercept = 0, linetype = "dashed") +
    labs(title = "Cross-validation Residuals", x = "Predicted", y = "Residual") +
    theme_minimal(base_size = 12)
  
  ggsave(filename = file.path(output_dir, paste0(ts, "_cv_residuals_plot.png")),
         plot = p_cv, width = 8, height = 6, dpi = 300)

  # ------------------------------------------------
  # STEP 6: Predict regression trend and kriging residuals
  # ------------------------------------------------
    
  # CONTINUE WORKING HERE
  
  
  # Define a gstat object for kriging using the fitted residual variogram
  g.resid <- gstat(
    id = c("residuals"),
    formula = residuals ~ 1,
    data = temp_shm.sf,
    nmax = 31,
    model = rvgm.temp
  )
  
  # Predict the temperature trend component using the regression model
  locTEMP.reg <- predict(lm.temp_shm, grids_sp)
  
  # OK of the regression residuals to model spatial autocorrelation
  locTEMP <- predict(g.resid, grids_sp, beta=1, BLUE=FALSE)
  
  # Combine the regression prediction with kriged residuals to get final RK predictions
  rk.pred <- locTEMP.reg + locTEMP$residuals.pred
  
  # Add the RK predictions as a new variable to the spatial grid object
  grids_sp$rk_pred <- rk.pred
  
  # Plot RK results overlayed with stations
  spplot(grids_sp, "rk_pred", main = "Regression Kriging Prediction (°C)",
         sp.layout = list("sp.points", station_coords, pch = 20, col = "white"))
  
  # ------------------------------------------------
  # STEP 7: Evaluate RK predictions at observation stations
  # ------------------------------------------------
  
  # Match station coordinates with observed stations only
  obs_coords <- st_coordinates(temp_shm.sf)
  obs_stations <- SpatialPoints(coords = obs_coords, proj4string = CRS(proj4string(grids_sp)))
  
  # Extract only at observed station locations
  rk_at_obs <- sp::over(obs_stations, grids_sp)
  
  # Combine predictions with observations
  rk_eval <- cbind(rk_at_obs, obs = temp_shm.sf$mh_temp)

  
  # Extract predicted values from the RK surface at station coordinates
  #rk_at_stations <- sp::over(station_coords, grids_sp)
  cat("Predicted rows:", nrow(rk_at_obs), "\n")
  cat("Observed rows :", length(temp_shm.sf$mh_temp), "\n")
  
  # Calculate prediction error
  rk_eval$residual <- rk_eval$obs - rk_eval$rk_pred
  
  # Metrics
  rmse <- sqrt(mean(rk_eval$residual^2, na.rm = TRUE))
  mae  <- mean(abs(rk_eval$residual), na.rm = TRUE)
  bias <- mean(rk_eval$residual, na.rm = TRUE)
  
  cat("RK RMSE :", round(rmse, 2), "\n")
  cat("RK MAE  :", round(mae, 2), "\n")
  cat("RK Bias :", round(bias, 2), "\n")
  
  ggplot(rk_eval, aes(x = rk_pred, y = residual)) +
    geom_point() +
    geom_hline(yintercept = 0, linetype = "dashed") +
    labs(title = "RK Prediction Residuals at Stations",
         x = "RK Predicted (°C)", y = "Residual (Observed - Predicted)")
}

# Save all LM metrics to a single CSV file
metrics_file <- file.path(output_dir, "lm_model_performance_summary.csv")
write.csv(lm_metrics_all, metrics_file, row.names = FALSE)

# Save all CV metrics to a single CSV file
cv_file <- file.path(output_dir, "cross_validation_metric.csv")
write.csv(cv_metrics_all, cv_file, row.names = FALSE)

```

WORKS WITH EMPTY RESULTS FOR THE PLOTS AND WEIRD KRIGING OUTPUTS

```{r main_loop}
# Get unique timestamps
timestamps <- unique(temp_hm$chour)[1:24]  # First 24 unique chour timestamps

# Loop through each timestamp
total_metrics <- data.frame()

for (ts in timestamps) {
  cat("\n\n=====================\nProcessing timestamp:", ts, "\n=====================\n")

  # ---- STEP 1: Select data ----
  sel_temp_hm <- temp_hm %>%
    filter(chour == ts) %>%
  

    
  # ---- STEP 1: Select data ----
  sel_temp_hm <- temp_hm %>%
    filter(chour == ts) %>%
    group_by(stationname) %>%
    slice_max(order_by = chour, n = 1, with_ties = FALSE) %>%
    ungroup()

  if (nrow(sel_temp_hm) < 5) next  # Skip if too few data points
  
  
    # Plot selected data
  plot(sel_temp_hm$mh_temp,
       pch = 21,                     
       col = "black",              
       bg = "grey",               
       cex = 1.4,               
       main = paste("Hourly Mean Temperature at 31 Stations\n( Timestamp:", unique(sel_temp_hm$hour),")"),
       xlab = "Station Index",
       ylab = "Mean Temperature (°C)",
       ylim = range(sel_temp_hm$mh_temp) + c(-0.5, 0.5),
       las = 1,                     
       bty = "l"                     
  )
  grid()
  
  # Save temperature plot
  temp_plot_file <- file.path(output_dir, paste0(ts, "_temperature_plot.png"))
  png(temp_plot_file)
  plot(sel_temp_hm$mh_temp,
       pch = 21,
       col = "black",
       bg = "grey",
       cex = 1.4,
       main = paste("Hourly Mean Temperature at 31 Stations\n( Timestamp:", unique(sel_temp_hm$hour),")"),
       xlab = "Station Index",
       ylab = "Mean Temperature (°C)",
       ylim = range(sel_temp_hm$mh_temp) + c(-0.5, 0.5),
       las = 1,
       bty = "l"
  )
  grid()
  dev.off()

  # ---- STEP 2: Add covariates ----
  r_brick <- brick(grids_sp)
  grid_terra <- rast(r_brick)
  extracted_vals <- terra::extract(grid_terra, sel_temp_hm)[,-1]
  temp_shm.ex <- cbind(as.data.frame(sel_temp_hm), extracted_vals)

  # ---- STEP 3: Fit linear model and prep spatial data ----
  lm.temp_shm <- lm(mh_temp ~ elev + canopy + bldg, data = temp_shm.ex)
  temp_shm.ex$residuals <- lm.temp_shm$residuals
  temp_shm.sf <- st_as_sf(temp_shm.ex)

  # ---- STEP 4: Anisotropy + Variogram ----
  varmap <- variogram(residuals ~ 1, data = temp_shm.sf, map = TRUE,
                      cutoff = sqrt(areaSpatialGrid(grids_sp)) / 2, 
                      width = 30 * grids_sp@grid@cellsize[1])

  anisotropy_plot_file <- file.path(output_dir, paste0(ts, "_anisotropy_lrm.png"))
  png(anisotropy_plot_file)
  plot(varmap, col.regions = grey(rev(seq(0, 1, 0.025))))
  dev.off()

  rv.temp <- variogram(residuals ~ 1, temp_shm.sf, alpha = c(0,90))
  rvgm.temp <- fit.variogram(rv.temp, vgm(psill=var(temp_shm.sf$residuals), "Exp", nugget=0))

  # ---- STEP 5: Cross Validation ----
  cv_resid <- krige.cv(residuals ~ 1, locations = temp_shm.sf, model = rvgm.temp,
                       nfold = nrow(temp_shm.sf), nmax = 10)
  cv_metrics <- data.frame(
    chour = ts,
    cv_rmse = sqrt(mean(cv_resid$residual^2)),
    cv_mae  = mean(abs(cv_resid$residual)),
    cv_bias = mean(cv_resid$residual)
  )
  write.csv(cv_resid, file.path(output_dir, paste0(ts, "_LOOCV_lrm.csv")), row.names = FALSE)
  write.csv(cv_metrics, file.path(output_dir, paste0(ts, "_LOOCV_metrics_lrm.csv")), row.names = FALSE)

  # ---- STEP 6: Regression Kriging ----
  locTEMP.reg <- predict(lm.temp_shm, grids_sp)
  g.resid <- gstat(id = "residuals", formula = residuals ~ 1, data = temp_shm.sf, model = rvgm.temp)
  locTEMP <- predict(g.resid, grids_sp, beta = 1, BLUE = FALSE)
  rk.pred <- locTEMP.reg + locTEMP$residuals.pred
  grids_sp$rk_pred <- rk.pred

  # ---- STEP 7: RK Evaluation ----
  # Extract RK predictions at station points
  rk_at_stations <- sp::over(station_coords, grids_sp)
  # Remove rows with missing RK predictions
  valid_idx <- which(!is.na(rk_at_stations$rk_pred))
  # Subset both RK predictions and observed temps
  # THIS COULD MEAN THAT PERFORMANCE EVALUATION IS DONE WITH LESS THAN 31 POINTS
  rk_eval <- cbind(rk_at_stations[valid_idx, , drop=FALSE],
                 obs = temp_shm.sf$mh_temp[valid_idx])
  rk_eval$residual <- rk_eval$obs - rk_eval$rk_pred
  rk_metrics <- data.frame(
    chour = ts,
    rk_rmse = sqrt(mean(rk_eval$residual^2, na.rm = TRUE)),
    rk_mae  = mean(abs(rk_eval$residual), na.rm = TRUE),
    rk_bias = mean(rk_eval$residual, na.rm = TRUE)
  )
  write.csv(rk_eval, file.path(output_dir, paste0(ts, "_RK_eval_lrm.csv")), row.names = FALSE)
  write.csv(rk_metrics, file.path(output_dir, paste0(ts, "_RK_metrics_lrm.csv")), row.names = FALSE)

  # ---- Optional RK map plot ----
  rk_plot_file <- file.path(output_dir, paste0(ts, "_RK_map_lrm.png"))
  png(rk_plot_file)
  spplot(grids_sp, "rk_pred", main = paste("RK Prediction -", ts))
  dev.off()

  total_metrics <- rbind(total_metrics, cbind(cv_metrics, rk_metrics[,2:4]))
}

# Save all combined metrics
write.csv(total_metrics, file.path(output_dir, "All_Timestamps_Metrics_lrm.csv"), row.names = FALSE)
```

```{r metrics_comparison_plot, echo=TRUE, message=FALSE}
# Convert timestamp to POSIXct if needed
total_metrics$chour <- as.POSIXct(total_metrics$chour)

# Pivot the data for ggplot
library(tidyr)

metrics_long <- total_metrics %>%
  select(chour, cv_rmse, rk_rmse, cv_mae, rk_mae, cv_bias, rk_bias) %>%
  pivot_longer(
    cols = -chour,
    names_to = c("type", "metric"),
    names_sep = "_",
    values_to = "value"
  )

# Plot
ggplot(metrics_long, aes(x = chour, y = value, color = type, group = type)) +
  geom_line(linewidth = 1) +
  geom_point() +
  facet_wrap(~ metric, scales = "free_y", ncol = 1) +
  labs(title = "Comparison of LOOCV and RK Metrics Across Timestamps",
       x = "Timestamp", y = "Metric Value", color = "Type") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


--------------------------------------------------------------------------------

  
```{r}
# Select one specific hourly mean for all the measurement stations

# Select, for each station, the record at its latest hour
sel_temp_hm <- temp_hm %>%
  group_by(stationname) %>%
  slice_max(order_by = chour, n = 1, with_ties = FALSE) %>%
  ungroup()

# Plot selected data
plot(sel_temp_hm$mh_temp,
     pch = 21,                     
     col = "black",              
     bg = "grey",               
     cex = 1.4,               
     main = paste("Hourly Mean Temperature at 31 Stations\n( Timestamp:", unique(sel_temp_hm$hour),")"),
     xlab = "Station Index",
     ylab = "Mean Temperature (°C)",
     ylim = range(sel_temp_hm$mh_temp) + c(-0.5, 0.5),
     las = 1,                     
     bty = "l"                     
)
grid()
```

```{r}
# Adding covariates to temperature data

# Convert Spatial object to a RasterBrick
r_brick <- brick(grids_sp)

# Convert the RasterBrick to a terra SpatRaster object
grid_terra <- rast(r_brick)

# Extract raster values at the point locations
extracted_vals <- terra::extract(grid_terra, sel_temp_hm)

# Remove the first column (ID)
extracted_vals <- extracted_vals[,-1]

# Combine the point data with the extracted raster values
temp_shm.ex <- cbind(as.data.frame(sel_temp_hm), extracted_vals)

str(temp_shm.ex)
```

```{r}
# Fit a linear model predicting mean hourly temperature
# using elevation, canopy height, and building height as predictors
lm.temp_shm <- lm(mh_temp ~ elev + canopy + bldg, data = temp_shm.ex)

# Show a summary of the fitted model (coefficients, R², p-values, etc.)
summary(lm.temp_shm)

# Save the model's residuals back into original df as new column
temp_shm.ex$residuals <- lm.temp_shm$residuals

# Inspect the structure of the updated data frame
str(temp_shm.ex)

# Convert the data frame into an 'sf' spatial object using the existing geometry
temp_shm.sf <- st_as_sf(temp_shm.ex)

# Confirm the resulting object's class
str(temp_shm.sf)
```

------------------------------------------------------------------------

Anisotropy

```{r}
# Compute a directional variogram map of the model residuals
# Helps to reveal spatial structure (anisotropy) not explained by the model

varmap <- variogram(residuals ~ 1, data = temp_shm.sf, map = TRUE,
                    # cutoff is half the spatial extent (or diameter) of the study area
                    cutoff = sqrt(areaSpatialGrid(grids_sp)) / 2, 
                    # scaled relative to the resolution of the grid
                    width = 30 * grids_sp@grid@cellsize[1])

cutoff_val <- sqrt(areaSpatialGrid(grids_sp)) / 2
width_val  <- 30 * grids_sp@grid@cellsize[1]

# Plot the computed variogram map
plot(varmap,
     col.regions = grey(rev(seq(0, 1, 0.025))),
     main = sprintf("Directional Variogram Map (cutoff: %.1f km, width: %.1f km)", 
                    cutoff_val / 1000, width_val / 1000))

# Compute directional variograms for North–South (0°) and East–West (90°)
rv.temp <- variogram(residuals ~ 1, temp_shm.sf, alpha=c(0,90))


rvgm.temp <- fit.variogram(rv.temp,
    vgm(psill=var(temp_shm.sf$residuals),
        "Exp", nugget=0, anis= c(p=90, s=0.5))) # p = direction, s = anisotropy ratio

# Plot the empirical and fitted directional variograms
plot(rv.temp, rvgm.temp,
     main = "Directional Variogram Fit (0° vs 90°)",
     plot.nu=FALSE, cex=2, pch="+", col="black")
```

Could the anisotropy which can be visualy identified in the E-W
direction be caused by the Neckar? Residuals are more dissimilar in this
direction indicating higher semivariance -\> more difference between
residuals

-   Anisotropy is present -\> Spatial correlation varies by direction
-   Stronger continuity in N–S -\> Lower semivariance at 0° -\> Data is
    more predictable N–S
-   Weaker continuity in E–W -\> Higher semivariance at 90° -\> Greater
    variation E–W (anisotropy) Model fit Reasonable in both panels which
    is a good basis for kriging

------------------------------------------------------------------------

Defining the geostatistical model for residuals

```{r}
g.resid <- gstat(
  id = c("residuals"),
  formula = residuals ~ 1,
  data = temp_shm.sf,
  nmax = 31,
  model = rvgm.temp
)
```

------------------------------------------------------------------------

Leave-One-Out Cross Validation applied to ordinary kriging residual
model

```{r}
# Cross-validation of the kriging model
cv_resid <- krige.cv(residuals ~ 1,
                     locations = temp_shm.sf,
                     model = rvgm.temp,
                     nfold = nrow(temp_shm.sf),       # or nrow(temp_shm.sf) for LOOCV
                     nmax = 10)

# Metrics
cv_rmse <- sqrt(mean(cv_resid$residual^2))
cv_mae  <- mean(abs(cv_resid$residual))
cv_me   <- mean(cv_resid$residual)

cat("Cross-Validation RMSE:", round(cv_rmse, 2), "\n")
cat("Cross-Validation MAE :", round(cv_mae, 2), "\n")
cat("Cross-Validation Bias:", round(cv_me, 2), "\n")

ggplot(cv_resid, aes(x = var1.pred, y = residual)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Cross-validation residuals", x = "Predicted", y = "Residual")
```

```{r}
# Predict the temperature trend component using the regression model
locTEMP.reg <- predict(lm.temp_shm, grids_sp)

# OK of the regression residuals to model spatial autocorrelation
locTEMP <- predict(g.resid, grids_sp, beta=1, BLUE=FALSE)

# Combine the regression prediction with kriged residuals to get final RK predictions
rk.pred <- locTEMP.reg + locTEMP$residuals.pred

# Add the RK predictions as a new variable to the spatial grid object
grids_sp$rk_pred <- rk.pred

# Convert station coordinates to a SpatialPoints object
coordinates(station_coords) <- ~ X + Y
proj4string(station_coords) <- CRS(proj4string(grids_sp))

# Plot RK results overlayed with stations
spplot(grids_sp, "rk_pred", main = "Regression Kriging Prediction (°C)",
       sp.layout = list("sp.points", station_coords, pch = 20, col = "white"))
```

Performance of final RK results

```{r}
# Extract predicted values from the RK surface at station coordinates
rk_at_stations <- sp::over(station_coords, grids_sp)

# Add observed values to the extracted predictions
rk_eval <- cbind(rk_at_stations, obs = temp_shm.sf$mh_temp)

# Calculate prediction error
rk_eval$residual <- rk_eval$obs - rk_eval$rk_pred

# Metrics
rmse <- sqrt(mean(rk_eval$residual^2, na.rm = TRUE))
mae  <- mean(abs(rk_eval$residual), na.rm = TRUE)
bias <- mean(rk_eval$residual, na.rm = TRUE)

cat("RK RMSE :", round(rmse, 2), "\n")
cat("RK MAE  :", round(mae, 2), "\n")
cat("RK Bias :", round(bias, 2), "\n")

ggplot(rk_eval, aes(x = rk_pred, y = residual)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "RK Prediction Residuals at Stations",
       x = "RK Predicted (°C)", y = "Residual (Observed - Predicted)")
```

------------------------------------------------------------------------

------------------------------------------------------------------------

CURRENTLY EXCLUDED. IS PROXIMITY TO WATER COVARIATE

Can be included, but destroys the results -> especially the visual appearance

```{r}
# Add proximity to water as another covariate

# Convert grid data to point features
points_vect <- as.points(grids)

# Convert point vector to sf object for spatial analysis
grid_sf <- st_as_sf(points_vect)

# Load river network
neckar <- st_read("../data/waterways/waterways_HD.gpkg")

# Reproject to 32632
neckar <- st_transform(neckar, crs = st_crs(temp))

# Clip Neckar river to extent of the grid (AOI)
neckar_clipped <- st_intersection(neckar, st_as_sfc(st_bbox(grid_sf)))

# Calculate minimum distance from each grid point to the Neckar river
grid_sf$dwater <- st_distance(grid_sf, neckar_clipped) %>%
  apply(1, min) %>%
  as.numeric()

# Cap at 500 meters to limit influence of distant points
#grid_sf$dwater[grid_sf$dwater > 500] <- NA

# Move 'dist_to_neckar' to first column
grid_sf <- grid_sf[, c("dwater", setdiff(names(grid_sf), "dwater"))]
```

```{r}
# Convert to SpatialPointsDataFrame
grids_sp <- as(grid_sf, "Spatial")

# Now to SpatialPixelsDataFrame
gridded(grids_sp) <- TRUE

# Convert to SpatialGridDataFrame
grids_sp <- as(grids_sp, "SpatialGridDataFrame")

str(grids_sp)
```

------------------------------------------------------------------------
